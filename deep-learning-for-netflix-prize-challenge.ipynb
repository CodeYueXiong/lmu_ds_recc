{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Short intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple\n",
      "Collecting keras==2.2.4\n",
      "  Using cached https://mirrors.aliyun.com/pypi/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312 kB)\n",
      "Requirement already satisfied: pyyaml in /environment/python/versions/3.7.4/lib/python3.7/site-packages (from keras==2.2.4) (5.3.1)\n",
      "Requirement already satisfied: scipy>=0.14 in /environment/python/versions/3.7.4/lib/python3.7/site-packages (from keras==2.2.4) (1.5.4)\n",
      "Requirement already satisfied: six>=1.9.0 in /environment/python/versions/3.7.4/lib/python3.7/site-packages (from keras==2.2.4) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /environment/python/versions/3.7.4/lib/python3.7/site-packages (from keras==2.2.4) (1.18.5)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /environment/python/versions/3.7.4/lib/python3.7/site-packages (from keras==2.2.4) (1.1.2)\n",
      "Requirement already satisfied: h5py in /environment/python/versions/3.7.4/lib/python3.7/site-packages (from keras==2.2.4) (2.10.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /environment/python/versions/3.7.4/lib/python3.7/site-packages (from keras==2.2.4) (1.18.5)\n",
      "Requirement already satisfied: six>=1.9.0 in /environment/python/versions/3.7.4/lib/python3.7/site-packages (from keras==2.2.4) (1.15.0)\n",
      "Collecting keras-applications>=1.0.6\n",
      "  Using cached https://mirrors.aliyun.com/pypi/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "Requirement already satisfied: h5py in /environment/python/versions/3.7.4/lib/python3.7/site-packages (from keras==2.2.4) (2.10.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /environment/python/versions/3.7.4/lib/python3.7/site-packages (from keras==2.2.4) (1.18.5)\n",
      "Requirement already satisfied: six>=1.9.0 in /environment/python/versions/3.7.4/lib/python3.7/site-packages (from keras==2.2.4) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /environment/python/versions/3.7.4/lib/python3.7/site-packages (from keras==2.2.4) (1.18.5)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /environment/python/versions/3.7.4/lib/python3.7/site-packages (from keras==2.2.4) (1.18.5)\n",
      "Installing collected packages: keras-applications, keras\n",
      "Successfully installed keras-2.2.4 keras-applications-1.0.8\n",
      "\u001b[33mWARNING: You are using pip version 20.3.1; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/environment/python/versions/3.7.4/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "## prepare for the shap package\n",
    "!pip install keras==2.2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/featurize/data/README\n",
      "/home/featurize/data/movie_titles.csv\n",
      "/home/featurize/data/combined_data_3.txt\n",
      "/home/featurize/data/qualifying.txt\n",
      "/home/featurize/data/netflix-prize-data.zip\n",
      "/home/featurize/data/combined_data_2.txt\n",
      "/home/featurize/data/combined_data_1.txt\n",
      "/home/featurize/data/probe.txt\n",
      "/home/featurize/data/combined_data_4.txt\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/home/featurize/data'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "## use eagerly to enable the numpy() function\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "import tensorflow.keras\n",
    "\n",
    "import tensorflow.keras.backend\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Reshape, Dot\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Concatenate, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening file: ../data/combined_data_1.txt\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-80fc321c3731>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mmovie_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m':'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovie_id\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m','\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "# DataFrame to store all imported data\n",
    "if not os.path.isfile('data.csv'):\n",
    "    data = open('data.csv', mode='w') # write all data into a csv file\n",
    "\n",
    "files = ['../data/combined_data_1.txt',\n",
    "         '../data/combined_data_2.txt',\n",
    "         '../data/combined_data_3.txt',\n",
    "         '../data/combined_data_4.txt']\n",
    "\n",
    "# Remove the line with movie_id: and add a new column of movie_id\n",
    "# Combine all data files into a csv file\n",
    "for file in files:\n",
    "  print(\"Opening file: {}\".format(file))\n",
    "  with open(file) as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if line.endswith(':'):\n",
    "            movie_id = line.replace(':', '')\n",
    "        else:\n",
    "            data.write(movie_id + ',' + line)\n",
    "            data.write('\\n')\n",
    "data.close()\n",
    "\n",
    "# Read all data into a pd dataframe, to generate a tabular data\n",
    "df = pd.read_csv('data.csv', names=['movie_id', 'user_id','rating','date'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1488844</td>\n",
       "      <td>3</td>\n",
       "      <td>2005-09-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>822109</td>\n",
       "      <td>5</td>\n",
       "      <td>2005-05-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>885013</td>\n",
       "      <td>4</td>\n",
       "      <td>2005-10-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>30878</td>\n",
       "      <td>4</td>\n",
       "      <td>2005-12-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>823519</td>\n",
       "      <td>3</td>\n",
       "      <td>2004-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100480502</th>\n",
       "      <td>17770</td>\n",
       "      <td>1790158</td>\n",
       "      <td>4</td>\n",
       "      <td>2005-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100480503</th>\n",
       "      <td>17770</td>\n",
       "      <td>1608708</td>\n",
       "      <td>3</td>\n",
       "      <td>2005-07-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100480504</th>\n",
       "      <td>17770</td>\n",
       "      <td>234275</td>\n",
       "      <td>1</td>\n",
       "      <td>2004-08-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100480505</th>\n",
       "      <td>17770</td>\n",
       "      <td>255278</td>\n",
       "      <td>4</td>\n",
       "      <td>2004-05-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100480506</th>\n",
       "      <td>17770</td>\n",
       "      <td>453585</td>\n",
       "      <td>2</td>\n",
       "      <td>2005-03-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100480507 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           movie_id  user_id  rating        date\n",
       "0                 1  1488844       3  2005-09-06\n",
       "1                 1   822109       5  2005-05-13\n",
       "2                 1   885013       4  2005-10-19\n",
       "3                 1    30878       4  2005-12-26\n",
       "4                 1   823519       3  2004-05-03\n",
       "...             ...      ...     ...         ...\n",
       "100480502     17770  1790158       4  2005-11-01\n",
       "100480503     17770  1608708       3  2005-07-19\n",
       "100480504     17770   234275       1  2004-08-07\n",
       "100480505     17770   255278       4  2004-05-28\n",
       "100480506     17770   453585       2  2005-03-10\n",
       "\n",
       "[100480507 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read all data into a pd dataframe, to generate a tabular data\n",
    "df = pd.read_csv('../netflix/data.csv', names=['movie_id', 'user_id','rating','date'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From dataframe df, let's take only a smaller dataset of 2000 top rated movies and 100000 top users (who gave the most rates) and save into new df: lite_rating_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>rating_u</th>\n",
       "      <th>rating_m</th>\n",
       "      <th>user</th>\n",
       "      <th>movie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5149</th>\n",
       "      <td>8</td>\n",
       "      <td>1488844</td>\n",
       "      <td>4</td>\n",
       "      <td>2005-05-12</td>\n",
       "      <td>2206</td>\n",
       "      <td>14910</td>\n",
       "      <td>5594</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5883</th>\n",
       "      <td>8</td>\n",
       "      <td>1227322</td>\n",
       "      <td>5</td>\n",
       "      <td>2005-05-31</td>\n",
       "      <td>4752</td>\n",
       "      <td>14910</td>\n",
       "      <td>4588</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6183</th>\n",
       "      <td>8</td>\n",
       "      <td>525356</td>\n",
       "      <td>4</td>\n",
       "      <td>2005-08-26</td>\n",
       "      <td>4913</td>\n",
       "      <td>14910</td>\n",
       "      <td>1946</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6310</th>\n",
       "      <td>8</td>\n",
       "      <td>401047</td>\n",
       "      <td>2</td>\n",
       "      <td>2005-06-15</td>\n",
       "      <td>2119</td>\n",
       "      <td>14910</td>\n",
       "      <td>1465</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7140</th>\n",
       "      <td>8</td>\n",
       "      <td>883478</td>\n",
       "      <td>5</td>\n",
       "      <td>2005-10-10</td>\n",
       "      <td>3222</td>\n",
       "      <td>14910</td>\n",
       "      <td>3261</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45663998</th>\n",
       "      <td>8163</td>\n",
       "      <td>778937</td>\n",
       "      <td>3</td>\n",
       "      <td>2005-06-10</td>\n",
       "      <td>1284</td>\n",
       "      <td>12553</td>\n",
       "      <td>2876</td>\n",
       "      <td>914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45668920</th>\n",
       "      <td>8163</td>\n",
       "      <td>1230845</td>\n",
       "      <td>3</td>\n",
       "      <td>2005-02-18</td>\n",
       "      <td>1277</td>\n",
       "      <td>12553</td>\n",
       "      <td>4604</td>\n",
       "      <td>914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45670283</th>\n",
       "      <td>8163</td>\n",
       "      <td>733887</td>\n",
       "      <td>4</td>\n",
       "      <td>2005-01-04</td>\n",
       "      <td>1779</td>\n",
       "      <td>12553</td>\n",
       "      <td>2703</td>\n",
       "      <td>914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45666732</th>\n",
       "      <td>8163</td>\n",
       "      <td>1645937</td>\n",
       "      <td>3</td>\n",
       "      <td>2005-02-01</td>\n",
       "      <td>1106</td>\n",
       "      <td>12553</td>\n",
       "      <td>6178</td>\n",
       "      <td>914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45665321</th>\n",
       "      <td>8163</td>\n",
       "      <td>1216109</td>\n",
       "      <td>4</td>\n",
       "      <td>2005-03-11</td>\n",
       "      <td>1252</td>\n",
       "      <td>12553</td>\n",
       "      <td>4547</td>\n",
       "      <td>914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9623889 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          movie_id  user_id  rating        date  rating_u  rating_m  user  \\\n",
       "5149             8  1488844       4  2005-05-12      2206     14910  5594   \n",
       "5883             8  1227322       5  2005-05-31      4752     14910  4588   \n",
       "6183             8   525356       4  2005-08-26      4913     14910  1946   \n",
       "6310             8   401047       2  2005-06-15      2119     14910  1465   \n",
       "7140             8   883478       5  2005-10-10      3222     14910  3261   \n",
       "...            ...      ...     ...         ...       ...       ...   ...   \n",
       "45663998      8163   778937       3  2005-06-10      1284     12553  2876   \n",
       "45668920      8163  1230845       3  2005-02-18      1277     12553  4604   \n",
       "45670283      8163   733887       4  2005-01-04      1779     12553  2703   \n",
       "45666732      8163  1645937       3  2005-02-01      1106     12553  6178   \n",
       "45665321      8163  1216109       4  2005-03-11      1252     12553  4547   \n",
       "\n",
       "          movie  \n",
       "5149          0  \n",
       "5883          0  \n",
       "6183          0  \n",
       "6310          0  \n",
       "7140          0  \n",
       "...         ...  \n",
       "45663998    914  \n",
       "45668920    914  \n",
       "45670283    914  \n",
       "45666732    914  \n",
       "45665321    914  \n",
       "\n",
       "[9623889 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lite_rating_df = pd.DataFrame()\n",
    "\n",
    "group = df.groupby('user_id')['rating'].count()\n",
    "top_users = group.sort_values(ascending=False)[:10000] # top users reschedule from 10000,rating_m correspnds to the movie_id\n",
    "\n",
    "group = df.groupby('movie_id')['rating'].count()\n",
    "top_movies = group.sort_values(ascending=False)[:2000] # top mivies reschedule from 2000\n",
    "\n",
    "lite_rating_df = df.join(top_users, rsuffix='_u', how='inner', on='user_id') # user id who gives the rating \n",
    "lite_rating_df = lite_rating_df.join(top_movies, rsuffix='_m', how='inner', on='movie_id') # movie id which receive the rating\n",
    "\n",
    "# Re-name the users and movies for uniform name from 0..2000 and 10000\n",
    "user_enc = LabelEncoder()\n",
    "lite_rating_df['user'] = user_enc.fit_transform(lite_rating_df['user_id'].values)\n",
    "movie_enc = LabelEncoder()\n",
    "lite_rating_df['movie'] = movie_enc.fit_transform(lite_rating_df['movie_id'].values)\n",
    "\n",
    "n_movies = lite_rating_df['movie'].nunique()\n",
    "n_users = lite_rating_df['user'].nunique()\n",
    "\n",
    "# print(n_movies, n_users)\n",
    "lite_rating_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = lite_rating_df[['user', 'movie']].values\n",
    "y = lite_rating_df['rating'].values\n",
    "\n",
    "# Split train and test data (for test model performance at last)\n",
    "X_training, X_test, y_training, y_test = train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "# Split train and validation data (to monitor model performance in training)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_training, y_training, test_size=0.1)\n",
    "\n",
    "# Set the embedding dimension d of Matrix factorization\n",
    "e_dimension = 50\n",
    "\n",
    "X_train_array = [X_train[:, 0], X_train[:, 1]]\n",
    "X_val_array = [X_val[:, 0], X_val[:, 1]]\n",
    "X_test_array = [X_test[:, 0], X_test[:, 1]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and train deep learning model\n",
    "\n",
    "The embeddings is used to represent each user and each movie in the data. \n",
    "The dot product of user embedding matrix (size: n_users x e_dimension) and movie embedding matrix (size: n_movies x e_dimension) is a good approximation of the rating from user for movie. The model's goal is to minimize the distqace between this dot product and the ratings (training target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1, 50)        500000      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 1, 50)        100000      input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 50)           0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 50)           0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 1)            0           reshape_2[0][0]                  \n",
      "                                                                 reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          256         dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            129         dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 600,385\n",
      "Trainable params: 600,385\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/20\n",
      "121799/121803 [============================>.] - ETA: 0s - loss: 0.7699 - root_mean_squared_error: 0.8642INFO:tensorflow:Assets written to: Model_2/assets\n",
      "121803/121803 [==============================] - 441s 4ms/step - loss: 0.7699 - root_mean_squared_error: 0.8642 - val_loss: 0.6958 - val_root_mean_squared_error: 0.8111\n",
      "Epoch 2/20\n",
      "121800/121803 [============================>.] - ETA: 0s - loss: 0.6805 - root_mean_squared_error: 0.7970INFO:tensorflow:Assets written to: Model_2/assets\n",
      "121803/121803 [==============================] - 442s 4ms/step - loss: 0.6805 - root_mean_squared_error: 0.7970 - val_loss: 0.6836 - val_root_mean_squared_error: 0.7956\n",
      "Epoch 3/20\n",
      "121803/121803 [==============================] - 441s 4ms/step - loss: 0.6679 - root_mean_squared_error: 0.7837 - val_loss: 0.6838 - val_root_mean_squared_error: 0.7924\n",
      "INFO:tensorflow:Assets written to: Model_2/assets\n"
     ]
    }
   ],
   "source": [
    "# Build user and movie embedding matrix\n",
    "user = Input(shape=(1,))\n",
    "u = Embedding(n_users, e_dimension, embeddings_initializer='he_normal',\n",
    "              embeddings_regularizer=l2(1e-6))(user)\n",
    "u = Reshape((e_dimension,))(u)\n",
    "movie = Input(shape=(1,))\n",
    "m = Embedding(n_movies, e_dimension, embeddings_initializer='he_normal',\n",
    "              embeddings_regularizer=l2(1e-6))(movie)\n",
    "m = Reshape((e_dimension,))(m)\n",
    "\n",
    "x = Dot(axes=1)([u, m])\n",
    "# Build last deep learning layers \n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(1)(x)\n",
    "\n",
    "model = Model(inputs=[user, movie], outputs=x)\n",
    "model.compile(loss='mean_squared_error', \n",
    "              optimizer=Adam(lr=0.001), \n",
    "              metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    "              )\n",
    "\n",
    "# Set up for early stop if the validation loss stop improving for more than 1 epoch\n",
    "callbacks_list = [tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                patience=1,\n",
    "                                                ),\n",
    "                  # Saves the weights after every epoch\n",
    "                  tf.keras.callbacks.ModelCheckpoint(  \n",
    "                      filepath='Model_2',\n",
    "                      monitor='val_loss',\n",
    "                      save_best_only=True,\n",
    "                      )]\n",
    "\n",
    "# Print model info summary\n",
    "model.summary()  \n",
    "\n",
    "history = model.fit(x=X_train_array, y=y_train, batch_size=64, epochs=20,\n",
    "                    verbose=1, \n",
    "                    callbacks=callbacks_list,\n",
    "                    validation_data=(X_val_array, y_val)\n",
    "                    )\n",
    "\n",
    "# Save the model (we should make a good habit of always saving our models after training)\n",
    "model.save(\"Model_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualize the training and validation loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training and validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the training and validation loss\n",
    "\n",
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "\n",
    "plt.plot(epochs, loss_values, 'ro', label='Training loss')\n",
    "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test loss in the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-4aac73a35426>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRootMeanSquaredError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "m = tf.keras.metrics.RootMeanSquaredError()\n",
    "m.update_state(model.predict(X_test_array), y_test)\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "tf.enable_eager_execution must be called at program startup.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-4422f404c209>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m## use eagerly to enable the numpy() function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_eager_execution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRootMeanSquaredError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/environment/python/versions/3.7.4/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36menable_eager_execution\u001b[0;34m(config, device_policy, execution_mode)\u001b[0m\n\u001b[1;32m   5848\u001b[0m         \u001b[0mdevice_policy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice_policy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5849\u001b[0m         \u001b[0mexecution_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexecution_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5850\u001b[0;31m         server_def=None)\n\u001b[0m\u001b[1;32m   5851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/environment/python/versions/3.7.4/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36menable_eager_execution_internal\u001b[0;34m(config, device_policy, execution_mode, server_def)\u001b[0m\n\u001b[1;32m   5907\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgraph_mode_has_been_used\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5908\u001b[0m       raise ValueError(\n\u001b[0;32m-> 5909\u001b[0;31m           \"tf.enable_eager_execution must be called at program startup.\")\n\u001b[0m\u001b[1;32m   5910\u001b[0m   \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_execution_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEAGER_MODE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5911\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: tf.enable_eager_execution must be called at program startup."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "## use eagerly to enable the numpy() function\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "m = keras.metrics.RootMeanSquaredError()\n",
    "m.update_state(new_model.predict(X_test_array), y_test)\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1, 50)        500000      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 50)        100000      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 50)           0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 50)           0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, 1)            0           reshape[0][0]                    \n",
      "                                                                 reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          256         dot[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 128)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            129         dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 600,385\n",
      "Trainable params: 600,385\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "new_model = tf.keras.models.load_model('../netflix/Model_1')\n",
    "\n",
    "# check the structure\n",
    "new_model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         x_user  x_movie\n",
      "0          2705     1498\n",
      "1          2920      980\n",
      "2          2895      524\n",
      "3          3942      779\n",
      "4          3875      221\n",
      "...         ...      ...\n",
      "7795345    1939     1327\n",
      "7795346    4543      375\n",
      "7795347    2650     1543\n",
      "7795348    9797      728\n",
      "7795349    7486       39\n",
      "\n",
      "[7795350 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from pandas.core.frame import DataFrame\n",
    "x_user = X_train_array[0] ## user\n",
    "x_movie = X_train_array[1] ## movie\n",
    "X_features = {\"x_user\" : x_user,\n",
    "            \"x_movie\" : x_movie}#将列表a，b转换成字典\n",
    "X_train_df = DataFrame(X_features)#将字典转换成为数据框\n",
    "print(X_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         y_train\n",
      "0              3\n",
      "1              3\n",
      "2              3\n",
      "3              5\n",
      "4              3\n",
      "...          ...\n",
      "7795345        3\n",
      "7795346        5\n",
      "7795347        2\n",
      "7795348        2\n",
      "7795349        4\n",
      "\n",
      "[7795350 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "y_train_df = {\"y_train\" : y_train}\n",
    "y_train_df = DataFrame(y_train_df)\n",
    "print(y_train_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import the SHAP library\n",
    "import shap\n",
    "\n",
    "# initialize js methods for visualization\n",
    "shap.initjs()\n",
    "\n",
    "# reload the model\n",
    "\n",
    "# create an instance of the DeepSHAP which is called DeepExplainer\n",
    "explainer_shap = shap.DeepExplainer(model=model,\n",
    "                                 data=X_train_array)\n",
    "\n",
    "# Fit the explainer on a subset of the data (you can try all but then gets slower)\n",
    "shap_values = explainer_shap.shap_values(\n",
    "#                                             X=.values,\n",
    "                                        X=X_train_df.values[:500],\n",
    "                                      ranked_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## individual attributions inferred by the model\n",
    "shap.force_plot(explainer_shap.expected_value,\n",
    "                shap_values[0][0],\n",
    "                feature_names=X_train_array.columns)\n",
    "\n",
    "shap.force_plot(explainer_shap.expected_value,\n",
    "                shap_values[0][0][1],\n",
    "                X_train_array.values[:500][0],\n",
    "                feature_names=X_train_array.columns,)\n",
    "\n",
    "shap.force_plot(explainer_shap.expected_value,\n",
    "                shap_values[0][0][1],\n",
    "                X_train_array.values[:500][0],\n",
    "                feature_names=X_train_array.columns,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## outputs of shapley values\n",
    "# to get the output value and base value\n",
    "record = 1 # this is just to pick one record in the dataset \n",
    "base_value = explainer_2.expected_value\n",
    "output= base_value + np.sum(shap_values[0][0][record])\n",
    "print('base value: ',base_value)\n",
    "print('output value: ',output)\n",
    "\n",
    "#sanity check that the ouput value is equal to the actual prediction\n",
    "print(np.round(output,decimals=1) == np.round(model.predict(X_train_array.values)[record],decimals=1))\n",
    "\n",
    "\n",
    "# to get the shape values or each feature\n",
    "shap_df = pd.DataFrame(list(dict(zip(X_train_array.columns.values,base_value)).items()),\n",
    "             columns=['features','shapvals']).sort_values(by='shapvals', ascending=True)\n",
    "print(shap_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the overall contribution of each feature variable\n",
    "shap.summary_plot(shap_values[0], X_train.values[:500], feature_names=X_train.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
